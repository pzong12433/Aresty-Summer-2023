//In anaconda terminal to access DLC
activate deeplabcut
ipython
import deeplabcut

//Create new project
deeplabcut.create_new_project('Master_Algorithm', 'Patrick_Zong', [r'C:\Users\Mark\Desktop\Aresty_2023_DLC_Videos_mp4\20210815-map2114-T_1.mp4']) //CRITICAL POINT: set config_file = whatever the path of your config file is. In this case "r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\config.yaml'".

//Add new videos
deeplabcut.add_new_videos(r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\config.yaml', [r'C:\Users\Mark\Desktop\Aresty_2023_DLC_Videos_mp4\20211013-map2144-T_1.mp4'])

//Extract frames
deeplabcut.extract_frames(r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\config.yaml', mode='automatic', algo='kmeans', userfeedback=True, crop=True) //CRITICAL POINT: When running the function extract_frames, if the parameter crop=True, then you will be asked to draw a box within the GUI (and this is written to the config.yaml file). 'userfeedback' allows the user to check which videos they wish to extract frames from. In this way, if you added more videos to the config.yaml file it does not, by default, extract frames (again) from every video.

//Label frames
deeplabcut.label_frames(r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\config.yaml') //CRITICAL POINT: You have to drag the folder in "Labled Data" into napari. It is advisable to consistently label similar spots (e.g., on a wrist that is very large, try to label the same location). 

//Check if frames are labeled
deeplabcut.check_labels(r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\config.yaml', visualizeindividuals=True)

//Create training dataset
deeplabcut.create_training_dataset(r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\config.yaml', augmenter_type='imgaug')

//Train dataset
deeplabcut.train_network(r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\config.yaml') //Edit parameters in pose_cfg.yaml file in interation folder before training!!!

//Evaluate dataset
deeplabcut.evaluate_network(r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\config.yaml',Shuffles=[1], plotting=True)

//Analyze videos
deeplabcut.analyze_videos(r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\config.yaml',[r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\videos'], save_as_csv=True)

//Filter pose data
deeplabcut.filterpredictions(r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\config.yaml', [r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\videos'])

//Plot pose data
deeplabcut.plot_trajectories(r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\config.yaml', [r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\videos'])

//Create labeled video
deeplabcut.create_labeled_video(r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\config.yaml', [r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\videos'], videotype='.mp4', filtered=True)

//Extract outlier frames
deeplabcut.extract_outlier_frames(r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\config.yaml', [r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\videos\20210815-map2114-T_1.mp4'], outlieralgorithm='jump') //CRITICAL POINT: If number of frames is more than 10000 set outlier algorithm = 'manual'. Delete previous machine iteration file before extracting!!! You must create new labeled data folder for each new video you analyze

//Refine labels
deeplabcut.refine_labels(r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\config.yaml') //CRITICAL POINT: Toggle visibility of previous machine iterations

//Merge dataset
deeplabcut.merge_datasets(r'C:\Users\Mark\Master_Algorithm-Patrick_Zong-2023-06-26\config.yaml') //CRITICAL POINT: Now you can create a new training dataset
